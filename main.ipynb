{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import (accuracy_score, classification_report,\n", "                             confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc)\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.preprocessing import label_binarize\n", "from sklearn.tree import DecisionTreeClassifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["warnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["file_path = '01_Data_Processed.csv'\n", "df = pd.read_csv(file_path)\n", "print(df.head())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['epoch (ms)'] = pd.to_datetime(df['epoch (ms)'], errors='coerce')\n", "print(df.head())\n", "# ============================== Plotting all values =============================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n", "sns.histplot(df['Accelerometer_x'], bins=50, ax=axes[0], color='r').set_title('Accelerometer X')\n", "sns.histplot(df['Accelerometer_y'], bins=50, ax=axes[1], color='g').set_title('Accelerometer Y')\n", "sns.histplot(df['Accelerometer_z'], bins=50, ax=axes[2], color='b').set_title('Accelerometer Z')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n", "sns.histplot(df['Gyroscope_x'], bins=50, ax=axes[0], color='r').set_title('Gyroscope X')\n", "sns.histplot(df['Gyroscope_y'], bins=50, ax=axes[1], color='g').set_title('Gyroscope Y')\n", "sns.histplot(df['Gyroscope_z'], bins=50, ax=axes[2], color='b').set_title('Gyroscope Z')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n", "sns.histplot(df['Participants'], bins=50, ax=axes[0], color='r').set_title('Participants')\n", "sns.histplot(df['Label'], bins=50, ax=axes[1], color='g').set_title('Label')\n", "sns.histplot(df['Category'], bins=50, ax=axes[2], color='b').set_title('Category')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.hist(df['Set'], bins=50, color='b')\n", "plt.title(\"Set\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["============================== CORELATION MATRIX =============================="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numeric_df = df.select_dtypes(include=[np.number])\n", "correlation_matrix = numeric_df.corr()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plotting the heatmap"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 8))\n", "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n", "plt.title('Correlation Heatmap')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"############################# Random Forest ##################################\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Feature and label selection"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df[['Accelerometer_x', 'Accelerometer_y', 'Accelerometer_z', 'Gyroscope_x', 'Gyroscope_y', 'Gyroscope_z']]\n", "y = df['Label']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the Random Forest model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Random_forest_model = RandomForestClassifier(n_estimators=10, random_state=10)\n", "Random_forest_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = Random_forest_model.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy pierwsza pr\u00f3ba: {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (Random Forest)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n", "n_classes = y_test_bin.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions and probability estimates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = Random_forest_model.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Random Forest')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n", "scores = cross_val_score(Random_forest_model, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Random Forest): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train Random Forest model with more estimators"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n", "Random_forest_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = Random_forest_model.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy: {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix for n_estimators=100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (Random Forest n_estimators=100)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass (Random Forest with n_estimators=100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n", "n_classes = y_test_bin.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions and probability estimates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = Random_forest_model.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves for the Random Forest model with n_estimators=100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Random Forest n_estimators=100')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation for n_estimators=100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores = cross_val_score(Random_forest_model, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Random Forest n_estimators=100): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"############################# LOGISTIC REGRESSION ##################################\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train logistic regression model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Logistic_regression_model = LogisticRegression()\n", "Logistic_regression_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = Logistic_regression_model.predict(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy: {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (Logistic Regression)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n", "n_classes = y_test_bin.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions and probability estimates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = Logistic_regression_model.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Multiclass Logistic Regression')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores = cross_val_score(Logistic_regression_model, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Logistic Regression): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train OVR model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Logistic_regression_model_ovr = LogisticRegression(multi_class='ovr', solver='lbfgs', random_state=100)\n", "Logistic_regression_model_ovr.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred_ovr = Logistic_regression_model_ovr.predict(X_test)\n", "accuracy_ovr = accuracy_score(y_test, y_pred_ovr)\n", "print(f'Accuracy (OVR): {accuracy_ovr:.2f}')\n", "print(classification_report(y_test, y_pred_ovr))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix for OVR"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm_ovr = confusion_matrix(y_test, y_pred_ovr)\n", "disp_ovr = ConfusionMatrixDisplay(confusion_matrix=cm_ovr)\n", "disp_ovr.plot()\n", "plt.title('Confusion Matrix (Logistic Regression OVR)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass (Logistic Regression OVR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob_ovr = Logistic_regression_model_ovr.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr_ovr = dict()\n", "tpr_ovr = dict()\n", "roc_auc_ovr = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr_ovr[i], tpr_ovr[i], _ = roc_curve(y_test_bin[:, i], y_prob_ovr[:, i])\n", "    roc_auc_ovr[i] = auc(fpr_ovr[i], tpr_ovr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves for the Logistic Regression OVR model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr_ovr[i], tpr_ovr[i], label=f'Class {i} ROC curve (area = {roc_auc_ovr[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Logistic Regression OVR')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation for OVR"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores_ovr = cross_val_score(Logistic_regression_model_ovr, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Logistic Regression OVR): {scores_ovr}')\n", "print(f'Srednia dokladnosc cross-validation OVR: {np.mean(scores_ovr):.2f}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"############################# KNN ##################################\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Feature and label selection"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df[['Accelerometer_x', 'Accelerometer_y', 'Accelerometer_z', 'Gyroscope_x', 'Gyroscope_y', 'Gyroscope_z']]\n", "y = df['Label']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train KNN model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["KNN_model = KNeighborsClassifier()\n", "KNN_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = KNN_model.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy: {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (KNN)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n", "n_classes = y_test_bin.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions and probability estimates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = KNN_model.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - KNN')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n", "scores = cross_val_score(KNN_model, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (KNN): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train KNN model with n_neighbors=1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["KNN_model = KNeighborsClassifier(n_neighbors=1)\n", "KNN_model.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = KNN_model.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy (n_neighbors=1): {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix for n_neighbors=1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (KNN n_neighbors=1)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass (KNN with n_neighbors=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = KNN_model.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves for the KNN model with n_neighbors=1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - KNN n_neighbors=1')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation for n_neighbors=1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores = cross_val_score(KNN_model, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (KNN n_neighbors=1): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"############################# Decision Tree Classifier ##################################\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Feature and label selection"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df[['Accelerometer_x', 'Accelerometer_y', 'Accelerometer_z', 'Gyroscope_x', 'Gyroscope_y', 'Gyroscope_z']]\n", "y = df['Label']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train Decision Tree model (max_depth=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Decision_tree = DecisionTreeClassifier(max_depth=1)\n", "Decision_tree.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = Decision_tree.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy (max_depth=1): {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (Decision Tree max_depth=1)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve for Multiclass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n", "n_classes = y_test_bin.shape[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predictions and probability estimates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = Decision_tree.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Decision Tree (max_depth=1)')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n", "scores = cross_val_score(Decision_tree, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Decision Tree max_depth=1): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train Decision Tree model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Decision_tree = DecisionTreeClassifier(max_depth=20, random_state=42, min_samples_split=5)\n", "Decision_tree.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Predict and evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = Decision_tree.predict(X_test)\n", "accuracy = accuracy_score(y_test, y_pred)\n", "print(f'Accuracy (max_depth=20): {accuracy:.2f}')\n", "print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Confusion Matrix"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cm = confusion_matrix(y_test, y_pred)\n", "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "disp.plot()\n", "plt.title('Confusion Matrix (Decision Tree max_depth=20)')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ROC Curve"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_prob = Decision_tree.predict_proba(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute ROC curve and ROC area for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot all ROC curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "for i in range(n_classes):\n", "    plt.plot(fpr[i], tpr[i], label=f'Class {i} ROC curve (area = {roc_auc[i]:.2f})')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot([0, 1], [0, 1], 'k--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver Operating Characteristic (ROC) - Decision Tree (max_depth=20)')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cross-validation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scores = cross_val_score(Decision_tree, X, y, cv=cv, scoring='accuracy')\n", "print(f'Cross-validation scores (Decision Tree max_depth=20): {scores}')\n", "print(f'Srednia dokladnosc cross-validation: {np.mean(scores):.2f}')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}